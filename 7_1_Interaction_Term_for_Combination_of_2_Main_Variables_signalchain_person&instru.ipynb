{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7.1 Interaction Term for Combination of 2 Main Variables_signalchain_person&instru.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Starrysmh/MARK5828-AdvertisingAnalytics-Project/blob/main/7_1_Interaction_Term_for_Combination_of_2_Main_Variables_signalchain_person%26instru.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8HmAwfDaAQz"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import os\n",
        "import statsmodels.api as sm\n",
        "from week2_helpers import variance_inflation_factor"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBCDq9g3oD-r"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import seaborn as sns; sns.set()\n",
        "from google.colab import files\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgITHRGg1cWw",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "8d208200-36fa-4c69-8efd-b55e61e1ec6f"
      },
      "source": [
        "print('Please upload the week2_helper python file')\n",
        "files.upload()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please upload the week2_helper python file\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-edb7a12c-d41f-44e2-a123-3ab18467d4c5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-edb7a12c-d41f-44e2-a123-3ab18467d4c5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving week2_helpers.py to week2_helpers.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'week2_helpers.py': b'\"\"\"\\r\\nSpecial Utility Functions for MARK5828 Week 2 Tutorial Content. The functions saved here are unnecessary for the students to learn, but they can read if they are curious.\\r\\nAuthor: James Lin\\r\\nSpecial Thanks: Daniel-Han Chan\\r\\n\"\"\"\\r\\n\\r\\nimport itertools\\r\\nfrom scipy.linalg.blas import ssyrk\\r\\nfrom scipy.linalg.lapack import spotrf, sposv\\r\\nimport numpy as np\\r\\nimport pandas as pd\\r\\n\\r\\nimport urllib.parse\\r\\nimport requests\\r\\n\\r\\ndef convert_to_seconds(time_str):\\r\\n    h, m, s = time_str.split(\":\")\\r\\n    return int(h) * 3600 + int(m) * 60 + round(float(s))\\r\\n\\r\\ndef get_source_language_v2(data):\\r\\n    return data[\"videos\"][0][\"insights\"][\"sourceLanguage\"]\\r\\n\\r\\ndef get_video_duration_v2(data):\\r\\n    return data[\"summarizedInsights\"][\"duration\"][\"seconds\"]\\r\\n\\r\\ndef get_faces_v2(data):\\r\\n    face_names = []\\r\\n    face_duration = []\\r\\n\\r\\n    for i, face in enumerate(data[\"summarizedInsights\"][\"faces\"]):\\r\\n        face_names.append(face[\"name\"])\\r\\n        face_duration.append(round(face[\"seenDuration\"]))\\r\\n\\r\\n    faces = dict(zip(face_names, face_duration))\\r\\n    sorted_faces = dict(sorted(faces.items(), key=lambda x: x[1], reverse=True))\\r\\n\\r\\n    return sorted_faces\\r\\n\\r\\ndef get_topics_v2(data):\\r\\n    \"\"\"Extracts Topics from the Analysed Video using Video Indexer version 2.\\r\\n\\r\\n    Arguments:\\r\\n        data {[json]} -- [Video Indexer Output]\\r\\n\\r\\n    Returns:\\r\\n        [Dictionary - (Topic Name: Topic Duration)] -- [Ranked from highest to lowest score]\\r\\n    \"\"\"\\r\\n    topic_names = []\\r\\n    topic_durations = []\\r\\n    for topic in data[\"summarizedInsights\"][\"topics\"]:\\r\\n        topic_names.append(topic[\"name\"])\\r\\n        duration = 0\\r\\n        for item in topic[\"appearances\"]:\\r\\n            duration += (item[\"endSeconds\"] - item[\"startSeconds\"])\\r\\n        topic_durations.append(round(duration))\\r\\n    topics = dict(zip(topic_names, topic_durations))\\r\\n    sorted_topics = dict(sorted(topics.items(), key=lambda x: x[1], reverse=True))\\r\\n\\r\\n    return sorted_topics\\r\\n\\r\\ndef get_keywords_v2(data):\\r\\n    \"\"\"Extracts Keywords from the Analysed Video using Video Indexer version 2.\\r\\n\\r\\n    Arguments:\\r\\n        data {[json]} -- [Video Indexer Output]\\r\\n\\r\\n    Returns:\\r\\n        [Dictionary - (Keyword Name: Keyword Duration)] -- [Ranked from highest to lowest score]\\r\\n    \"\"\"\\r\\n    keyword_names = []\\r\\n    keyword_durations = []\\r\\n    for keyword in data[\"summarizedInsights\"][\"keywords\"]:\\r\\n        keyword_names.append(keyword[\"name\"])\\r\\n        duration = 0\\r\\n        for item in keyword[\"appearances\"]:\\r\\n            duration += (item[\"endSeconds\"] - item[\"startSeconds\"])\\r\\n        keyword_durations.append(round(duration))\\r\\n    keywords = dict(zip(keyword_names, keyword_durations))\\r\\n    sorted_keywords = dict(sorted(keywords.items(), key=lambda x: x[1], reverse=True))\\r\\n\\r\\n    return sorted_keywords\\r\\n\\r\\ndef get_labels_v2(data):\\r\\n    \"\"\"Extract Labels from the Analysed Video using Video Indexer\\r\\n\\r\\n    Arguments:\\r\\n        data {[json]} -- [Video Indexer Output]\\r\\n\\r\\n    Returns:\\r\\n        [Dictionary - (Label Name: Label SeenDuration)] -- [Ranked from highest to lowest]\\r\\n    \"\"\"\\r\\n\\r\\n    label_names = []\\r\\n    label_durations = []\\r\\n    for label in data[\"summarizedInsights\"][\"labels\"]:\\r\\n        label_names.append(label[\"name\"])\\r\\n        duration = 0\\r\\n        for item in label[\"appearances\"]:\\r\\n            duration += (item[\"endSeconds\"] - item[\"startSeconds\"])\\r\\n        label_durations.append(round(duration))\\r\\n    labels = dict(zip(label_names, label_durations))\\r\\n    sorted_labels = dict(sorted(labels.items(), key=lambda x: x[1], reverse=True))\\r\\n\\r\\n    return sorted_labels\\r\\n\\r\\ndef get_brands_v2(data):\\r\\n    \"\"\"[summary]\\r\\n\\r\\n    Arguments:\\r\\n        data {[type]} -- [description]\\r\\n\\r\\n    Returns:\\r\\n        Dictionary -- [Key - Brand Name: Value - (Seen Duration (s), Confidence, Description)]\\r\\n    \"\"\"\\r\\n\\r\\n    brand_name = []\\r\\n    brand_duration = []\\r\\n    for brand in data[\"summarizedInsights\"][\"brands\"]:\\r\\n        brand_name.append(brand[\"name\"])\\r\\n        brand_duration.append(round(brand[\"seenDuration\"]))\\r\\n\\r\\n    brands = dict(zip(brand_name, brand_duration))\\r\\n    sorted_brands = dict(sorted(brands.items(), key=lambda x: x[1], reverse=True))\\r\\n\\r\\n    return sorted_brands\\r\\n\\r\\ndef get_emotions_v2(data):\\r\\n    emotion_names = []\\r\\n    emotion_durations = []\\r\\n    for emotion in data[\"summarizedInsights\"][\"emotions\"]:\\r\\n        emotion_names.append(emotion[\"type\"])\\r\\n        duration = 0\\r\\n        for item in emotion[\"appearances\"]:\\r\\n            duration += (item[\"endSeconds\"] - item[\"startSeconds\"])\\r\\n        emotion_durations.append(round(duration))\\r\\n    emotions = dict(zip(emotion_names, emotion_durations))\\r\\n    sorted_emotions = dict(sorted(emotions.items(), key=lambda x: x[1], reverse=True))\\r\\n\\r\\n    return sorted_emotions\\r\\n\\r\\n\\r\\ndef get_sentiments_v2(data):\\r\\n    sentiments = {\\r\\n        \"Negative\": 0,\\r\\n        \"Neutral\": 0,\\r\\n        \"Positive\": 0\\r\\n    }\\r\\n\\r\\n    for sentiment in data[\"summarizedInsights\"][\"sentiments\"]:\\r\\n        for item in sentiment[\"appearances\"]:\\r\\n            sentiments[sentiment[\"sentimentKey\"]] += round(item[\"endSeconds\"] - item[\"startSeconds\"])\\r\\n\\r\\n    return sentiments\\r\\n\\r\\ndef get_audio_effects_v2(data):\\r\\n    effect_names = []\\r\\n    effect_durations = []\\r\\n    for effect in data[\"summarizedInsights\"][\"audioEffects\"]:\\r\\n        effect_names.append(effect[\"audioEffectKey\"])\\r\\n        duration = 0\\r\\n        for item in effect[\"appearances\"]:\\r\\n            duration += (item[\"endSeconds\"] - item[\"startSeconds\"])\\r\\n        effect_durations.append(round(duration))\\r\\n    effects = dict(zip(effect_names, effect_durations))\\r\\n    sorted_effects = dict(sorted(effects.items(), key=lambda x: x[1], reverse=True))\\r\\n\\r\\n    return sorted_effects\\r\\n\\r\\ndef get_statistics_v2(data):\\r\\n    return data[\"summarizedInsights\"][\"statistics\"]\\r\\n\\r\\ndef get_ocr_v2(data):\\r\\n    try:\\r\\n        ocr_names = []\\r\\n        ocr_durations = []\\r\\n        ocr_left = []\\r\\n        ocr_top = []\\r\\n        ocr_width = []\\r\\n        ocr_height = []\\r\\n        for ocr in data[\"videos\"][0][\"insights\"][\"ocr\"]:\\r\\n            ocr_names.append(ocr[\"text\"])\\r\\n            ocr_left.append(ocr[\"left\"])\\r\\n            ocr_top.append(ocr[\"top\"])\\r\\n            ocr_width.append(ocr[\"width\"])\\r\\n            ocr_height.append(ocr[\"height\"])\\r\\n            duration = 0\\r\\n            for item in ocr[\"instances\"]:\\r\\n                duration += convert_to_seconds(item[\"end\"]) - convert_to_seconds(item[\"start\"])\\r\\n            ocr_durations.append(round(duration))\\r\\n        ocrs = dict(zip(ocr_names, zip(ocr_durations, ocr_left, ocr_top, ocr_width, ocr_height)))\\r\\n        sorted_ocrs = dict(sorted(ocrs.items(), key=lambda x: x[1], reverse=True))\\r\\n    except Exception as e:\\r\\n        sorted_ocrs = {}\\r\\n\\r\\n    return sorted_ocrs\\r\\n\\r\\ndef get_transcript_v2(data):\\r\\n    \"\"\"[summary]\\r\\n\\r\\n    Arguments:\\r\\n        data {[type]} -- [description]\\r\\n\\r\\n    Returns:\\r\\n        [String] -- [Transcript for the whole video]\\r\\n    \"\"\"\\r\\n\\r\\n    try:\\r\\n        transcript = \"\"\\r\\n        for block in data[\"videos\"][0][\"insights\"][\"transcript\"]:\\r\\n            transcript += (block[\"text\"] + \" \")\\r\\n    except Exception as e:\\r\\n        transcript = \"\"\\r\\n    return transcript\\r\\n\\r\\ndef get_shots_v2(data):\\r\\n    shot_id = []\\r\\n    shot_duration = []\\r\\n    for shot in data[\"videos\"][0][\"insights\"][\"shots\"]:\\r\\n        shot_id.append(shot[\"id\"])\\r\\n        duration = 0\\r\\n        for item in shot[\"keyFrames\"]:\\r\\n            for item_ in item[\"instances\"]:\\r\\n                duration += convert_to_seconds(item_[\"end\"]) - convert_to_seconds(item_[\"start\"])\\r\\n        shot_duration.append(round(duration))\\r\\n    shots = dict(zip(shot_id, shot_duration))\\r\\n    sorted_shots = dict(sorted(shots.items(), key=lambda x: x[1], reverse=True))\\r\\n\\r\\n    return sorted_shots\\r\\n\\r\\ndef get_frame_patterns_v2(data):\\r\\n    try:\\r\\n        frame_names = []\\r\\n        frame_durations = []\\r\\n        for frame in data[\"videos\"][0][\"insights\"][\"framePatterns\"]:\\r\\n            frame_names.append(frame[\"patternType\"])\\r\\n            duration = 0\\r\\n            for item in frame[\"instances\"]:\\r\\n                duration += convert_to_seconds(item[\"end\"]) - convert_to_seconds(item[\"start\"])\\r\\n            frame_durations.append(round(duration))\\r\\n        frames = dict(zip(frame_names, frame_durations))\\r\\n        sorted_frames = dict(sorted(frames.items(), key=lambda x: x[1], reverse=True))\\r\\n    except Exception as e:\\r\\n#         print(\"Error: \" + data[\"name\"] + \" - \" + str(e))\\r\\n        sorted_frames = {}\\r\\n\\r\\n    return sorted_frames\\r\\n\\r\\ndef get_text_content_mod_v2(data):\\r\\n    return data[\"videos\"][0][\"insights\"][\"textualContentModeration\"]\\r\\n\\r\\ndef get_video_variables_v2(idx, data):\\r\\n    return {\\r\\n        \"id\": idx,\\r\\n        \"indexer_source_language\": get_source_language_v2(data),\\r\\n        \"indexer_duration\": get_video_duration_v2(data),\\r\\n        \"indexer_faces\": get_faces_v2(data),\\r\\n        \"indexer_topics\": get_topics_v2(data),\\r\\n        \"indexer_keywords\": get_keywords_v2(data),\\r\\n        \"indexer_labels\": get_labels_v2(data),\\r\\n        \"indexer_brands\": get_brands_v2(data),\\r\\n        \"indexer_emotions\": get_emotions_v2(data),\\r\\n        \"indexer_sentiment_positive\": get_sentiments_v2(data)[\"Positive\"],\\r\\n        \"indexer_sentiment_neutral\": get_sentiments_v2(data)[\"Neutral\"],\\r\\n        \"indexer_sentiment_negative\": get_sentiments_v2(data)[\"Negative\"],\\r\\n        \"indexer_audio_effects\": get_audio_effects_v2(data),\\r\\n        \"indexer_statistics\": get_statistics_v2(data),\\r\\n        \"indexer_ocr\": get_ocr_v2(data), \\r\\n        \"indexer_transcript\": get_transcript_v2(data),\\r\\n        \"indexer_shots\": get_shots_v2(data),\\r\\n        \"indexer_frame_patterns\": get_frame_patterns_v2(data),\\r\\n        \"indexer_content_moderation_banned_words_count\": get_text_content_mod_v2(data)[\"bannedWordsCount\"],\\r\\n        \"indexer_content_moderation_banned_words_ratio\": get_text_content_mod_v2(data)[\"bannedWordsRatio\"]\\r\\n    }\\r\\n\\r\\n\\r\\ndef create_item_dummies(df, column, num):\\r\\n    print(\"Processing: \" + str(column))\\r\\n    df_copy = df.copy()\\r\\n\\r\\n    item_counts = df_copy[column].apply(lambda d: {k: 1 for k in d.keys()})\\r\\n    item_iterator = itertools.accumulate(item_counts, lambda x, y: { k: x.get(k, 0) + y.get(k, 0) for k in set(x) | set(y) })\\r\\n    final_item_count = {}\\r\\n    for final_item_count in item_iterator:\\r\\n        pass\\r\\n    sorted_item_count = sorted(final_item_count.items(), key=lambda kv: kv[1], reverse=True)\\r\\n\\r\\n    sorted_item_keys = [item[0] for item in sorted_item_count]\\r\\n    for item_key in sorted_item_keys[:num]:\\r\\n        new_column_name = column + \"_\" + item_key.lower().replace(\" \", \"_\")\\r\\n        df_copy[new_column_name] = df[column].apply(item_match, args=(item_key,))\\r\\n\\r\\n    return df_copy\\r\\n\\r\\n\\r\\ndef item_match(item_dict, item_value):\\r\\n    if item_value in item_dict.keys():\\r\\n        return item_dict[item_value]\\r\\n    else:\\r\\n        return 0\\r\\n\\r\\ndef get_ocr_area(item):\\r\\n    if item == 0:\\r\\n        return 0\\r\\n    else:\\r\\n        _, _, _, width, height = item\\r\\n        return width * height\\r\\n\\r\\ndef get_ocr_duration(item):\\r\\n    if item == 0:\\r\\n        return 0\\r\\n    else:\\r\\n        return item[0]\\r\\n\\r\\ndef video_indexer_to_df(json_list, video_ids=[]):\\r\\n    \"\"\"\\r\\n    Inputs\\r\\n        json_list: List of Video Indexer Data\\r\\n        video_ids: [Optional] List of Video IDs\\r\\n\\r\\n    Outputs\\r\\n        Clean DataFrame representation of the json_list\\r\\n    \"\"\"\\r\\n    if len(video_ids) == 0:\\r\\n        video_ids = range(len(json_list))\\r\\n    video_indexer_attributes = []\\r\\n    for idx, item in zip(video_ids, json_list):\\r\\n        video_indexer_attributes.append(get_video_variables_v2(idx, item))\\r\\n\\r\\n    df_indexer = pd.DataFrame(video_indexer_attributes)\\r\\n\\r\\n    # Play around with numerical values\\r\\n    create_item_dummies_list = {\\r\\n        \"indexer_audio_effects\": 50,\\r\\n        \"indexer_brands\": 50,\\r\\n        \"indexer_emotions\": 50,\\r\\n        \"indexer_frame_patterns\": 50,\\r\\n        \"indexer_keywords\": 50,\\r\\n        \"indexer_labels\": 50,\\r\\n        \"indexer_ocr\": 50,\\r\\n        \"indexer_topics\": 50,\\r\\n    }\\r\\n\\r\\n\\r\\n    for key, value in create_item_dummies_list.items():\\r\\n        df_indexer = create_item_dummies(df_indexer, key, value)\\r\\n\\r\\n    for column in df_indexer.columns:\\r\\n        if \"indexer_ocr_\" in column:\\r\\n            df_indexer[column + \"_area\"] = df_indexer[column].apply(get_ocr_area)\\r\\n            df_indexer[column] = df_indexer[column].apply(get_ocr_duration)\\r\\n\\r\\n    df_indexer[\"indexer_num_faces\"] = df_indexer[\"indexer_faces\"].apply(lambda x: len(x))\\r\\n    df_indexer[\"indexer_num_shots\"] = df_indexer[\"indexer_shots\"].apply(lambda x: len(x))\\r\\n    df_indexer[\"indexer_transcript\"] = df_indexer[\"indexer_transcript\"].apply(lambda x: len(x.split()))\\r\\n    df_indexer[\"indexer_statistics_correspondence_count\"] = df_indexer[\"indexer_statistics\"].apply(lambda x: x[\"correspondenceCount\"])\\r\\n\\r\\n    columns_remove = [\\r\\n        \"indexer_audio_effects\",\\r\\n        \"indexer_brands\",\\r\\n        \"indexer_emotions\",\\r\\n        \"indexer_faces\",\\r\\n        \"indexer_frame_patterns\",\\r\\n        \"indexer_keywords\",\\r\\n        \"indexer_labels\",\\r\\n        \"indexer_ocr\",\\r\\n        \"indexer_shots\",\\r\\n        \"indexer_statistics\",\\r\\n        \"indexer_topics\"\\r\\n    ]\\r\\n\\r\\n    df_indexer_clean = df_indexer.drop(columns=columns_remove, axis=1)\\r\\n    return df_indexer_clean\\r\\n\\r\\n\\r\\nfrom scipy.linalg.lapack import spotrf, spotri\\r\\nfrom scipy.linalg.blas import ssyrk, ssymm\\r\\nfrom scipy import stats\\r\\nimport pandas as pd\\r\\n\\r\\ndef p_value(X, y):\\r\\n\\t\\r\\n\\tn, p = X.shape\\r\\n\\t\\r\\n\\t## Get Cholesky factor to check multicollinearity\\r\\n\\tif type(X) is pd.DataFrame:\\r\\n\\t\\ttry:\\r\\n\\t\\t\\tX[\"Bias\"];\\r\\n\\t\\texcept:\\r\\n\\t\\t\\tX[\"Bias\"] = 1\\r\\n\\t\\t\\tp += 1\\r\\n\\t\\tnames = np.array(X.columns)\\r\\n\\t\\tX = X.values\\r\\n\\telse:\\r\\n\\t\\tp += 1\\r\\n\\t\\tnames = np.arange(p, dtype = int).astype(str)\\r\\n\\t\\tnames[-1] = \"Bias\"\\r\\n\\t\\tX = np.hstack((X, np.ones((n,1), dtype = X.dtype)))\\r\\n\\tif type(y) is pd.Series:\\r\\n\\t\\ty = y.values\\r\\n\\t\\r\\n\\t## Get choleksy factor\\r\\n\\tXTX = ssyrk(a = X.T, alpha = 1)\\r\\n\\ttemp = XTX.T.copy().T\\r\\n\\terror = 1\\r\\n\\tselect = np.ones(p, dtype = np.bool_)\\r\\n\\tVIF = np.ones(p, dtype = np.float32)\\r\\n\\t\\r\\n\\tadd = 1e4\\r\\n\\twhile error != 0:\\r\\n\\t\\tC, error = spotrf(a = temp)\\r\\n\\t\\tif error != 0:\\r\\n\\t\\t\\terror -= 1\\r\\n\\t\\t\\tselect[error] = False\\r\\n\\t\\t\\tVIF[error] /= (error + 1e-6)\\r\\n\\t\\t\\ttemp[error, error] += add\\r\\n\\t\\t\\terror += 1\\r\\n\\t\\t\\tadd *= 10\\r\\n\\tdel temp, C\\r\\n\\treturn select, VIF\\r\\n\\r\\n\\tXTX = XTX[select][:,select]\\r\\n\\tC, error = spotrf(a = XTX, overwrite_a = True)\\r\\n\\t\\r\\n\\tinv, error = spotri(c = C)\\r\\n\\t\\r\\n\\t\\r\\n\\t## Actual regression coefficients\\r\\n\\tXTy = X[:,select].T @ y\\r\\n\\tcoef = ssymm(alpha = 1, a = inv, b = XTy).ravel()\\r\\n\\tdel XTy\\r\\n\\ttheta = np.zeros(p, dtype = X.dtype)\\r\\n\\ttheta[select] = coef\\r\\n\\t\\r\\n\\t## Standard error\\r\\n\\ty_hat = X @ theta\\r\\n\\te = (y - y_hat)**2\\r\\n\\tMSE = (e.sum())/(n- p)\\r\\n\\tSE = MSE**0.5\\r\\n\\t\\r\\n\\t## Coefficient errors\\r\\n\\tdiags = (inv.diagonal())**0.5 * SE\\r\\n\\tdel inv\\r\\n\\tgood = diags!=0\\r\\n\\tT = np.zeros(np.sum(select), dtype = X.dtype)\\r\\n\\tT[good] = coef[good]/diags[good]\\r\\n\\r\\n\\tp_values = 2*(stats.t.sf(abs(T), n-p))  # 2*(1-cdf)\\r\\n\\tdel T\\r\\n\\tp = np.ones(p, dtype = X.dtype)\\r\\n\\tp[select] = p_values\\r\\n\\t\\r\\n\\t## print out\\r\\n\\tdiag = np.zeros(X.shape[1], dtype = X.dtype)\\r\\n\\tdiag[select] = diags\\r\\n\\tdel diags\\r\\n\\t\\r\\n\\tdf = pd.DataFrame({\"Names\":names, \"Coef\":theta, \"P_values\":p,\"SE\":diag})\\r\\n\\tdel diag\\r\\n\\t\\r\\n\\tdf[\"Significant\"] = \"\"\\r\\n\\tdf.loc[p<=0.001, \"Significant\"] = \"+++\"\\r\\n\\tdf.loc[(p<=0.01) & (p>0.001), \"Significant\"] = \"++\"\\r\\n\\tdf.loc[(p<=0.1) & (p>0.01), \"Significant\"] = \"+\"\\r\\n\\tdf.loc[(p<=0.2) & (p>0.1), \"Significant\"] = \"-\"\\r\\n\\tdf.loc[p>0.2, \"Significant\"] = \"---\"\\r\\n\\tdf.sort_values(by = [\"P_values\",\"Coef\"], ascending = [True, False], inplace = True)\\r\\n\\tdf = df.round(5)\\r\\n\\tdel p\\r\\n\\t\\r\\n\\t\\r\\n\\t## Print formula\\r\\n\\tgood = df[\"Significant\"]==\"+++\"\\r\\n\\tgood = good.index[good]\\r\\n\\tstring = \"y = \"\\r\\n\\tend = False\\r\\n\\tj = 0\\r\\n\\tfor i in good:\\r\\n\\t\\tcoef, name = df.loc[i][[\"Coef\",\"Names\"]]\\r\\n\\t\\tif name != \"Bias\":\\r\\n\\t\\t\\tif coef < 0:\\r\\n\\t\\t\\t\\tstring += \"-{}*[{}] \".format(abs(coef), name)\\r\\n\\t\\t\\telse:\\r\\n\\t\\t\\t\\tstring += \"+{}*[{}] \".format(coef, name)\\r\\n\\t\\telse:\\r\\n\\t\\t\\tbias = coef\\r\\n\\t\\t\\tend = True\\r\\n\\t\\tj += 1\\r\\n\\t\\tif j > 10: break\\r\\n\\tif end:\\r\\n\\t\\tif bias < 0:\\r\\n\\t\\t\\tstring += \"-{}\".format(abs(bias))\\r\\n\\t\\telse:\\r\\n\\t\\t\\tstring += \"+{}\".format(bias)\\r\\n\\t\\r\\n\\tprint(string)\\r\\n\\treturn df\\r\\n\\r\\n\\r\\n\\r\\ndef multicollinearity(X, y):\\r\\n\\tn, p = X.shape\\r\\n\\t\\r\\n\\t## Get Cholesky factor to check multicollinearity\\r\\n\\tif type(X) is pd.DataFrame:\\r\\n\\t\\ttry:\\r\\n\\t\\t\\tX[\"Bias\"];\\r\\n\\t\\texcept:\\r\\n\\t\\t\\tX[\"Bias\"] = 1\\r\\n\\t\\t\\tp += 1\\r\\n\\t\\tnames = np.array(X.columns)\\r\\n\\t\\tX = X.values\\r\\n\\telse:\\r\\n\\t\\tp += 1\\r\\n\\t\\tnames = np.arange(p, dtype = int).astype(str)\\r\\n\\t\\tnames[-1] = \"Bias\"\\r\\n\\t\\tX = np.hstack((X, np.ones((n,1), dtype = X.dtype)))\\r\\n\\tif type(y) is pd.Series:\\r\\n\\t\\ty = y.values\\r\\n\\t\\r\\n\\t## Get choleksy factor\\r\\n\\tXTX = ssyrk(a = X.T, alpha = 1)\\r\\n\\ttemp = XTX.T.copy().T\\r\\n\\terror = 1\\r\\n\\tselect = np.ones(p, dtype = np.bool_)\\r\\n\\tVIF = np.ones(p, dtype = np.float32)\\r\\n\\t\\r\\n\\tadd = 1e4\\r\\n\\twhile error != 0:\\r\\n\\t\\tC, error = spotrf(a = temp)\\r\\n\\t\\tif error != 0:\\r\\n\\t\\t\\terror -= 1\\r\\n\\t\\t\\tselect[error] = False\\r\\n\\t\\t\\tVIF[error] /= (error + 1e-6)\\r\\n\\t\\t\\ttemp[error, error] += add\\r\\n\\t\\t\\terror += 1\\r\\n\\t\\t\\tadd *= 10\\r\\n\\tdel temp, C\\r\\n\\treturn select, VIF\\r\\n\\r\\n\\r\\nfrom scipy.linalg.blas import ssyrk\\r\\nfrom scipy.linalg.lapack import sposv\\r\\nimport numpy as np, pandas as pd\\r\\n\\r\\ndef variance_inflation_factor(X):\\r\\n    df = X.copy()\\r\\n    if type(X) is pd.DataFrame:\\r\\n        X = X.values\\r\\n    n, p = X.shape\\r\\n    XTX = X.T @ X\\r\\n\\r\\n    select = np.ones(p, dtype = bool)\\r\\n\\r\\n    temp = XTX.copy()\\r\\n    error = 1\\r\\n    largest = XTX.diagonal().max() // 2\\r\\n    add = largest\\r\\n    maximum = np.finfo(np.float32).max\\r\\n    k = largest // 4\\r\\n\\r\\n    while error != 0:\\r\\n        C, error = spotrf(a = temp.T)\\r\\n        if error != 0:\\r\\n            error -= 1\\r\\n            select[error] = False\\r\\n            temp[error, error] += add\\r\\n            error += 1\\r\\n\\t\\t\\t\\r\\n            add += k\\r\\n            add *= k\\r\\n            if add > maximum:\\r\\n                add = largest\\r\\n        k += 1\\r\\n\\r\\n    VIF = np.empty(p, dtype = np.float32)\\r\\n    means = np.mean(X, axis = 0)\\r\\n\\t\\r\\n    for i in range(p):\\r\\n        curr = select.copy()\\r\\n        if curr[i] == False:\\r\\n            VIF[i] = np.inf\\r\\n            continue\\r\\n        curr[i] = False\\r\\n\\t\\t\\r\\n        XX = XTX[curr]\\r\\n        xtx = XX[:, curr]\\r\\n        xty = XX[:,i]\\r\\n        y_x = X[:,i]\\r\\n\\r\\n        theta_x = sposv(xtx, xty)[1]\\r\\n        y_hat = X[:,curr] @ theta_x\\r\\n\\t\\t\\r\\n        SS_res = y_x-y_hat\\r\\n        SS_res = np.einsum(\\'i,i\\', SS_res, SS_res)\\r\\n\\t\\t#SS_res = np.sum((y_x - y_hat)**2)\\r\\n\\t\\t\\r\\n        SS_tot = y_x - means[i]\\r\\n        SS_tot = np.einsum(\\'i,i\\', SS_tot, SS_tot)\\r\\n\\t\\t#SS_tot = np.sum((y_x - np.mean(y_x))**2)\\r\\n        if SS_tot == 0:\\r\\n            R2 = 1\\r\\n            VIF[i] = np.inf\\r\\n        else:\\r\\n            R2 = 1 - (SS_res/SS_tot)\\r\\n            VIF[i] = 1/(1-R2)\\r\\n    df_vif = pd.DataFrame({\"vif\": VIF})\\r\\n    df_vif = df_vif.set_index(df.columns)\\r\\n    return df_vif\\r\\n\\t#return VIF\\r\\n\\r\\nclass VideoIndexerClientV2():\\r\\n    \"\"\"Microsoft Video Indexer Wrapper Class\"\"\"\\r\\n    def __init__(self, subscription_key, location, account_id):\\r\\n        self._subscription_key = subscription_key\\r\\n        self._location = location\\r\\n        self._account_id = account_id\\r\\n\\r\\n    def get_account_access_token(self, allow_edit=True):\\r\\n        \"\"\"Gets user account access token, which is required to make calls to APIs listed under \"operation\".\"\"\"\\r\\n\\r\\n        headers = {\\r\\n            \\'Ocp-Apim-Subscription-Key\\': self._subscription_key,\\r\\n        }\\r\\n\\r\\n        params = urllib.parse.urlencode({\\r\\n            \\'allowEdit\\': str(allow_edit),\\r\\n        })\\r\\n        try:\\r\\n            url = \"https://api.videoindexer.ai/auth/\" + self._location + \"/Accounts/\" + self._account_id + \"/AccessToken?\"\\r\\n            return requests.get(url, params=params, headers=headers).json()\\r\\n        except Exception as e:\\r\\n            print(\"Get Account Access Token Error: \" + str(e))\\r\\n            return None\\r\\n\\r\\n    def delete_video(self, video_id):\\r\\n        \"\"\"\\r\\n        Deletes an uploaded Video Indexer video provided its video_id.\\r\\n        NOTE: video_id is NOT the same as external_id. Use \"get_video_id_by_external_id()\" to get the video_id, or\\r\\n        find it in the .JSON output file.\\r\\n        \"\"\"\\r\\n        access_token = self.get_account_access_token()\\r\\n        headers = {\\r\\n        }\\r\\n\\r\\n        params = urllib.parse.urlencode({\\r\\n            \\'accessToken\\': access_token,\\r\\n        })\\r\\n\\r\\n        try:\\r\\n            url = \"https://api.videoindexer.ai/\" + self._location + \"/Accounts/\" + self._account_id + \"/Videos/\" + video_id + \"?\"\\r\\n            return requests.delete(url, params=params, headers=headers)\\r\\n        except Exception as e:\\r\\n            print(\"Delete Video Error: \" + video_id + \": \" + str(e))\\r\\n            return None\\r\\n\\r\\n    def list_videos(self):\\r\\n        \"\"\"\\r\\n        Lists all the videos that are currently uploaded on Microsoft Video Indexer.\\r\\n        https://www.videoindexer.ai/\\r\\n        \"\"\"\\r\\n        access_token = self.get_account_access_token()\\r\\n        headers = {\\r\\n            # Request headers\\r\\n            \\'Content-Type\\': \\'application/json\\',\\r\\n        }\\r\\n\\r\\n        params = urllib.parse.urlencode({\\r\\n            \\'accessToken\\': access_token,\\r\\n        })\\r\\n\\r\\n        try:\\r\\n            url = \"https://api.videoindexer.ai/\" + self._location + \"/Accounts/\" + self._account_id + \"/Videos?\"\\r\\n            return requests.get(url, params=params, headers=headers).json()\\r\\n        except Exception as e:\\r\\n            print(\"List Videos Error: \" + str(e))\\r\\n            return None\\r\\n\\r\\n    def search_videos(self, external_id):\\r\\n        \"\"\"\\r\\n        Searches for an uploaded video by its external_id.\\r\\n        \"\"\"\\r\\n        access_token = self.get_account_access_token()\\r\\n        headers = {}\\r\\n\\r\\n        params = urllib.parse.urlencode({\\r\\n            # Request parameters\\r\\n            \\'externalId\\': external_id,\\r\\n            \\'accessToken\\': access_token,\\r\\n        })\\r\\n\\r\\n        try:\\r\\n            url = \"https://api.videoindexer.ai/\" + self._location + \"/Accounts/\" + self._account_id + \"/Videos/Search?\"\\r\\n            return requests.get(url, params=params, headers=headers).json()\\r\\n        except Exception as e:\\r\\n            print(\"Search Videos Error: \" + external_id + \": \" + str(e))\\r\\n            return None\\r\\n\\r\\n    def get_video_id_by_external_id(self, external_id):\\r\\n        \"\"\"\\r\\n        Retrieves the video_id (used for get_video_index) from the external_id.\\r\\n        \"\"\"\\r\\n        access_token = self.get_account_access_token()\\r\\n        headers = {}\\r\\n\\r\\n        params = urllib.parse.urlencode({\\r\\n            # Request parameters\\r\\n            \\'externalId\\': external_id,\\r\\n            \\'accessToken\\': access_token,\\r\\n        })\\r\\n\\r\\n        try:\\r\\n            url = \"https://api.videoindexer.ai/\" + self._location + \"/Accounts/\" + self._account_id + \"/Videos/GetIdByExternalId?\"\\r\\n            return requests.get(url, params=params, headers=headers).json()\\r\\n        except Exception as e:\\r\\n            print(\"Get Video Id by External Id Error: \" + external_id + \": \" + str(e))\\r\\n            return None\\r\\n\\r\\n\\r\\n    def get_video_index(self, video_id):\\r\\n        \"\"\"\\r\\n        Retrieves the JSON output file detailing the Video Indexer\\'s analysis results.\\r\\n        See https://docs.microsoft.com/en-us/azure/media-services/video-indexer/video-indexer-output-json-v2\\r\\n        \"\"\"\\r\\n        access_token = self.get_account_access_token()\\r\\n        headers = {}\\r\\n\\r\\n        params = urllib.parse.urlencode({\\r\\n            \\'accessToken\\': access_token,\\r\\n        })\\r\\n\\r\\n        try:\\r\\n            url = \"https://api.videoindexer.ai/\" + self._location + \"/Accounts/\" + self._account_id + \"/Videos/\" + video_id + \"/Index?\"\\r\\n            return requests.get(url, params=params, headers=headers).json()\\r\\n        except Exception as e:\\r\\n            print(\"Get Video Index Error: \" + video_id + \": \" + str(e))\\r\\n            return None\\r\\n\\r\\n    def upload_video(self, name, video_url, description, external_id, privacy=\"Private\"):\\r\\n        \"\"\"\\r\\n        Upload a video to Video Indexer using an online url.\\r\\n        \"\"\"\\r\\n        access_token = self.get_account_access_token()\\r\\n        headers = {\\r\\n            # Request headers\\r\\n            \\'Content-Type\\': \\'multipart/form-data\\',\\r\\n        }\\r\\n\\r\\n        params = urllib.parse.urlencode({\\r\\n            # Request parameters\\r\\n            \\'accessToken\\': access_token,\\r\\n            \\'videoUrl\\': video_url,\\r\\n            \\'name\\': name,\\r\\n            \\'description\\': description,\\r\\n            \\'externalId\\': external_id,\\r\\n            \\'privacy\\': privacy,\\r\\n        })\\r\\n\\r\\n        try:\\r\\n            print(\"Uploading Video: \" + external_id)\\r\\n            url = \"https://api.videoindexer.ai/\" + self._location + \"/Accounts/\" + self._account_id + \"/Videos?\"\\r\\n            return requests.post(url, params=params, headers=headers).json()\\r\\n        except Exception as e:\\r\\n            print(\"Upload Video Error \" + external_id + \": \" + str(e))\\r\\n            return None\\r\\n\\r\\n    def upload_video_local(self, name, video_path, description, external_id, privacy=\"Private\"):\\r\\n        \"\"\"\\r\\n        Upload a video to Video Indexer using a video path local to your computer (or google colaboratory)\\r\\n        \"\"\"\\r\\n        access_token = self.get_account_access_token()\\r\\n        headers = {\\r\\n            # Request headers\\r\\n            \\'Content-Type\\': \\'multipart/form-data\\',\\r\\n        }\\r\\n\\r\\n        params = urllib.parse.urlencode({\\r\\n            \\'location\\' : self._location,\\r\\n            \\'accountId\\' : self._account_id,\\r\\n            \\'accessToken\\': access_token,\\r\\n            \\'name\\': name,\\r\\n            \\'description\\': description,\\r\\n            \\'externalId\\': external_id,\\r\\n            \\'privacy\\': privacy,\\r\\n        })\\r\\n\\r\\n        try:\\r\\n            print(\"Uploading Video: \" + name)\\r\\n\\r\\n            url = \"https://api.videoindexer.ai/\" + self._location + \"/Accounts/\" + self._account_id + \"/Videos?\"\\r\\n\\r\\n            return requests.post(url, params=params,files={\\'file0\\': open(video_path, \\'rb\\')}).json()\\r\\n\\r\\n        except Exception as e:\\r\\n            print(\"Upload Video Error \" + name + \": \" + str(e))\\r\\n            return None\\r\\n\\r\\n\\r\\n    def get_faces(self, video_id):\\r\\n        \"\"\"\\r\\n        NOTE: Used for Public Videos only\\r\\n        Retrieves urls for faces detected in a video.\\r\\n        \"\"\"\\r\\n        access_token = self.get_account_access_token()\\r\\n        face_urls = []\\r\\n        try:\\r\\n            data = self.get_video_index(access_token=access_token, video_id=video_id)\\r\\n            for item in data[\"summarizedInsights\"][\"faces\"]:\\r\\n                face_urls.append(\"https://www.videoindexer.ai/api/v2/accounts/\" + self._account_id + \"/videos/\" + data[\"id\"] + \"/thumbnails/\" + item[\"thumbnailId\"] + \"/\")\\r\\n            return face_urls\\r\\n        except Exception as e:\\r\\n            print(\"Get Faces Error \" + str(video_id) + \": \" + str(e))\\r\\n            return face_urls'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLcw2CiS17Mw"
      },
      "source": [
        "from week2_helpers import variance_inflation_factor"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXbTYvxRC_ET"
      },
      "source": [
        "def file_reader():\n",
        "  \n",
        "  uploaded_file=files.upload()\n",
        "  uploaded_file=list(uploaded_file.keys())[0]\n",
        "  if uploaded_file.endswith('csv'):\n",
        "    data=pd.read_csv(uploaded_file)\n",
        "  else:\n",
        "    data=pd.read_excel(uploaded_file)\n",
        "  return data"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS90oouF2e6M",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "2ca1a29d-7fd6-475f-c685-9e32dd6fb6dc"
      },
      "source": [
        "print('Please upload the merged data')\n",
        "merged_data=file_reader()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please upload the merged data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c71f6675-2948-46a2-8863-df2f7e740faf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c71f6675-2948-46a2-8863-df2f7e740faf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving regression_data_signalchain.csv to regression_data_signalchain.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i_WNrvUkOZq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGsVdpMIaaGI"
      },
      "source": [
        "dummy_data = merged_data[[\"likeCount\",\"yesPerson\",\"YesFinalInstrument\"]]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcvOdCMIfXwd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "432f812a-a400-497e-8727-7d2d7ea815f6"
      },
      "source": [
        "dummy_data"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>likeCount</th>\n",
              "      <th>yesPerson</th>\n",
              "      <th>YesFinalInstrument</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>90</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2032</th>\n",
              "      <td>226</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2033</th>\n",
              "      <td>228</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2034</th>\n",
              "      <td>237</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2035</th>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2036</th>\n",
              "      <td>371</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2037 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      likeCount  yesPerson  YesFinalInstrument\n",
              "0            90          0                   0\n",
              "1            75          0                   0\n",
              "2            48          0                   0\n",
              "3            28          0                   1\n",
              "4            58          0                   0\n",
              "...         ...        ...                 ...\n",
              "2032        226          0                   1\n",
              "2033        228          0                   1\n",
              "2034        237          0                   1\n",
              "2035        258          0                   1\n",
              "2036        371          0                   1\n",
              "\n",
              "[2037 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp-tgylAe-BQ"
      },
      "source": [
        "#H1: with person in the post incrreases social media ad popularity. \n",
        "#H2: with instrument in the post decreases social media ad popularity. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUlbiYjpbnzA"
      },
      "source": [
        "Y=dummy_data['likeCount']\n",
        "X=dummy_data.drop(['likeCount'],axis=1).astype(float)\n",
        "X=sm.add_constant(X)\n",
        "model=sm.OLS(Y,X)\n",
        "results=model.fit()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72sCwzCzcV6x"
      },
      "source": [
        "vif = variance_inflation_factor(X)\n",
        "vif_store=vif.drop('const',axis=0)\n",
        "vif_store.sort_values('vif',ascending=False)\n",
        "df_coeffs = pd.DataFrame({\"Coefficients\": results.params, \"p\": results.pvalues, \"vif\": vif[\"vif\"]})\n",
        "if 'const' in df_coeffs.index:\n",
        "    df_coeffs = df_coeffs.drop(\"const\", axis=0)\n",
        "df_coeffs_sorted = df_coeffs.reindex(df_coeffs[\"p\"].sort_values(ascending=True).index)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTm6MS1LdnLP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STBqqwZ4dqON",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "03fd904c-673e-4b4a-e85c-84bffc4e425d"
      },
      "source": [
        "df_coeffs_sorted "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Coefficients</th>\n",
              "      <th>p</th>\n",
              "      <th>vif</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>YesFinalInstrument</th>\n",
              "      <td>28.289326</td>\n",
              "      <td>2.393280e-09</td>\n",
              "      <td>1.010037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yesPerson</th>\n",
              "      <td>-14.902132</td>\n",
              "      <td>6.609719e-03</td>\n",
              "      <td>1.010037</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Coefficients             p       vif\n",
              "YesFinalInstrument     28.289326  2.393280e-09  1.010037\n",
              "yesPerson             -14.902132  6.609719e-03  1.010037"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOjQyGHenEk9"
      },
      "source": [
        "in this regression result, we can see the effect of present of person and instrument on number of likes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI8AtQAdeg_H"
      },
      "source": [
        "# Approach 1 - make interaction variable X3 = X1 x X2\n",
        "#H1: person incrreases social media ad popularity. \n",
        "#H2: instrument decreases social media ad popularity. \n",
        "#H3: There is synergy effect between person and instrument in increasing social media ad popularity. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaIJ7moPex_M"
      },
      "source": [
        "dummy_data2 = dummy_data.copy()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHoNuAJ-gYe4"
      },
      "source": [
        "#sometimes, to avoid multicollinearity issue, we can reduce the value of brightness and saturation by their average before making interaction term\n",
        "for col in [\"YesFinalInstrument\",\"yesPerson\"]:\n",
        "  avg = dummy_data2[col].mean()\n",
        "  dummy_data2[col] = dummy_data2[col].apply(lambda x:x-avg)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LQmOS-if3lE"
      },
      "source": [
        "#create the interaction term for brightness and saturation\n",
        "dummy_data2[\"BxS\"] = dummy_data2[\"YesFinalInstrument\"] * dummy_data2[\"yesPerson\"]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHXYSRVhgDwu"
      },
      "source": [
        "Y=dummy_data2['likeCount']\n",
        "X=dummy_data2.drop(['likeCount'],axis=1).astype(float)\n",
        "X=sm.add_constant(X)\n",
        "model=sm.OLS(Y,X)\n",
        "results=model.fit()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWAZTEYjgG8d"
      },
      "source": [
        "vif = variance_inflation_factor(X)\n",
        "vif_store=vif.drop('const',axis=0)\n",
        "vif_store.sort_values('vif',ascending=False)\n",
        "df_coeffs = pd.DataFrame({\"Coefficients\": results.params, \"p\": results.pvalues, \"vif\": vif[\"vif\"]})\n",
        "if 'const' in df_coeffs.index:\n",
        "    df_coeffs = df_coeffs.drop(\"const\", axis=0)\n",
        "df_coeffs_sorted = df_coeffs.reindex(df_coeffs[\"p\"].sort_values(ascending=True).index)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnduDWOmgR0E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "f09cb4cb-8377-473f-f7cd-211e86060cff"
      },
      "source": [
        "df_coeffs_sorted"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Coefficients</th>\n",
              "      <th>p</th>\n",
              "      <th>vif</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>YesFinalInstrument</th>\n",
              "      <td>28.304890</td>\n",
              "      <td>3.075367e-09</td>\n",
              "      <td>1.024819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yesPerson</th>\n",
              "      <td>-14.929041</td>\n",
              "      <td>7.425110e-03</td>\n",
              "      <td>1.042779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BxS</th>\n",
              "      <td>-0.336473</td>\n",
              "      <td>9.782550e-01</td>\n",
              "      <td>1.051911</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Coefficients             p       vif\n",
              "YesFinalInstrument     28.304890  3.075367e-09  1.024819\n",
              "yesPerson             -14.929041  7.425110e-03  1.042779\n",
              "BxS                    -0.336473  9.782550e-01  1.051911"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2-LH58mnLlR"
      },
      "source": [
        "in this regression result, we can see the effect of brightness by itself, saturation by itself, and the combination of brightness and saturation on number of likes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEJv7CtbiMnF"
      },
      "source": [
        "#Research Question: Does combination of Brightness and Saturation can affect the number of likes? (Approach 2)\n",
        "# Approach 2 - make HH, HL, LH, LL (For baseline, it is good to choose the variable with the smallest coeffient)\n",
        "#H1: High brightness & High Satulation increases social media ad popularity. \n",
        "#H2: High brightness & Low Satulation decreases social media ad popularity. \n",
        "#H3: Low brightness and High Satulation increases social media ad popularity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgHpqtfGiO0-"
      },
      "source": [
        "dummy_data3 = dummy_data.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aQxgTMwiROR"
      },
      "source": [
        "#convert into binary (0-1) using their mean as a cut off value\n",
        "#Where 1 means high value, 0 mean low value\n",
        "for col in [\"brightness\",\"saturation\"]:\n",
        "  avg = dummy_data3[col].mean()\n",
        "  dummy_data3[col] = dummy_data3[col].apply(lambda x:1 if x>avg else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktr3YjTSmXYj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkaAOqJQikcY"
      },
      "source": [
        "#create the interaction term for the combination between High-High, High-Low,Low-High,Low-Low\n",
        "main_variable = [\"brightness\",\"saturation\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5nVr2r7lYg8"
      },
      "source": [
        "dummy_data3[\"High-High\"] = dummy_data3[main_variable[0]] * dummy_data3[main_variable[1]] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF3MwpHKlfEj"
      },
      "source": [
        "dummy_data3[\"High-Low\"] = dummy_data3[main_variable[0]] * (1 - dummy_data3[main_variable[1]] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfMx5A3ol24i"
      },
      "source": [
        "dummy_data3[\"Low-High\"] = (1-dummy_data3[main_variable[0]]) * dummy_data3[main_variable[1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-zb-mMclxXF"
      },
      "source": [
        "dummy_data3[\"Low-Low\"] = (1-dummy_data3[main_variable[0]]) * (1 - dummy_data3[main_variable[1]] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U9w3nlNmCJf"
      },
      "source": [
        "#among 4 combination, drop 1 of them for regression as a baseline + original variable\n",
        "Y=dummy_data3['likeCount']\n",
        "X=dummy_data3.drop(['likeCount','Low-Low',\"brightness\",\"saturation\"],axis=1).astype(float)\n",
        "X=sm.add_constant(X)\n",
        "model=sm.OLS(Y,X)\n",
        "results=model.fit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SRq4N55mSA2"
      },
      "source": [
        "vif = variance_inflation_factor(X)\n",
        "vif_store=vif.drop('const',axis=0)\n",
        "vif_store.sort_values('vif',ascending=False)\n",
        "df_coeffs = pd.DataFrame({\"Coefficients\": results.params, \"p\": results.pvalues, \"vif\": vif[\"vif\"]})\n",
        "if 'const' in df_coeffs.index:\n",
        "    df_coeffs = df_coeffs.drop(\"const\", axis=0)\n",
        "df_coeffs_sorted = df_coeffs.reindex(df_coeffs[\"p\"].sort_values(ascending=True).index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4HkD2jcmS37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "2a085a71-5de2-4c50-9e58-d1ddecaa1dbc"
      },
      "source": [
        "df_coeffs_sorted"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Coefficients</th>\n",
              "      <th>p</th>\n",
              "      <th>vif</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>High-Low</th>\n",
              "      <td>100.0</td>\n",
              "      <td>0.454371</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Low-High</th>\n",
              "      <td>-100.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>High-High</th>\n",
              "      <td>-50.0</td>\n",
              "      <td>0.704833</td>\n",
              "      <td>1.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Coefficients         p  vif\n",
              "High-Low          100.0  0.454371  1.8\n",
              "Low-High         -100.0  0.500000  1.6\n",
              "High-High         -50.0  0.704833  1.6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjVN6kZtoRLI"
      },
      "source": [
        " in this regression result, we can see the effect of 3 different pair of brightness and saturation on number of likes\n"
      ]
    }
  ]
}